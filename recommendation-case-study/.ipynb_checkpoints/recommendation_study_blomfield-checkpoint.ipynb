{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each user is potentially interested in watching one or more of the movies specified in `requests.json`. Our job is to **decide which movie or movies to recommend to these users**.\n",
    "\n",
    "Use a combination of matrix factorization model (ALS) and a cold start model (using user and movie metadata) to fill in the NaN values and predict ratings for these movies.\n",
    "\n",
    "Your predictions will be scored as follows:\n",
    "\n",
    "1. Each user may watch movies from your list, starting with the highest predicted rating.\n",
    "2. Your model will be scored based on how well the users liked the movies they watched."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-02T18:30:37.341964Z",
     "start_time": "2019-07-02T18:30:37.207015Z"
    }
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS, ALSModel\n",
    "\n",
    "# K Means\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import calinski_harabaz_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import calinski_harabaz_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-02T20:06:28.092041Z",
     "start_time": "2019-07-02T20:06:27.965200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LICENSE             movies.dat          ratings.json        users.dat\r\n",
      "README              \u001b[31mmovies_metadata.csv\u001b[m\u001b[m requests.json\r\n",
      "movies.csv          ratings.csv         users.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-02T18:32:46.263681Z",
     "start_time": "2019-07-02T18:32:43.813550Z"
    }
   },
   "outputs": [],
   "source": [
    "spark = (pyspark.sql.SparkSession.builder.master(\"local[*]\").getOrCreate())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Import Movies CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-02T18:36:00.354846Z",
     "start_time": "2019-07-02T18:35:59.956052Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(_c0=0, movie_id=2, title='Jumanji (1995)', genres=\"Adventure|Children's|Fantasy\")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = 'data/movies.csv'\n",
    "movies = spark.read.csv(file, inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-02T18:36:17.377714Z",
     "start_time": "2019-07-02T18:36:17.287125Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(_c0=0, movie_id=2, title='Jumanji (1995)', genres=\"Adventure|Children's|Fantasy\"),\n",
       " Row(_c0=1, movie_id=3, title='Grumpier Old Men (1995)', genres='Comedy|Romance'),\n",
       " Row(_c0=2, movie_id=4, title='Waiting to Exhale (1995)', genres='Comedy|Drama')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Import Movies_metadata CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-02T18:36:46.354284Z",
     "start_time": "2019-07-02T18:36:45.899560Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "file = 'data/movies_metadata.csv'\n",
    "movies_metadata = spark.read.csv(file, inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-02T18:36:55.132267Z",
     "start_time": "2019-07-02T18:36:55.060848Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(adult='False', belongs_to_collection=\"{'id': 10194, 'name': 'Toy Story Collection', 'poster_path': '/7G9915LfUQ2lVfwMEEhDsn3kT4B.jpg', 'backdrop_path': '/9FBwqcd9IRruEDUrTdcaafOMKUq.jpg'}\", budget='30000000', genres=\"[{'id': 16, 'name': 'Animation'}, {'id': 35, 'name': 'Comedy'}, {'id': 10751, 'name': 'Family'}]\", homepage='http://toystory.disney.com/toy-story', id='862', imdb_id='tt0114709', original_language='en', original_title='Toy Story', overview=\"Led by Woody, Andy's toys live happily in his room until Andy's birthday brings Buzz Lightyear onto the scene. Afraid of losing his place in Andy's heart, Woody plots against Buzz. But when circumstances separate Buzz and Woody from their owner, the duo eventually learns to put aside their differences.\", popularity='21.946943', poster_path='/rhIRbceoE9lR4veEXuwCC2wARtG.jpg', production_companies=\"[{'name': 'Pixar Animation Studios', 'id': 3}]\", production_countries=\"[{'iso_3166_1': 'US', 'name': 'United States of America'}]\", release_date='1995-10-30', revenue='373554033', runtime='81.0', spoken_languages=\"[{'iso_639_1': 'en', 'name': 'English'}]\", status='Released', tagline=None, title='Toy Story', video='False', vote_average='7.7', vote_count='5415')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_metadata.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Import Ratings CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-02T18:41:19.291663Z",
     "start_time": "2019-07-02T18:41:18.232891Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "file = 'data/ratings.csv'\n",
    "ratings = spark.read.csv(file, inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-02T18:41:28.478062Z",
     "start_time": "2019-07-02T18:41:28.415890Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(_c0=0, movie_id=858, rating=4, timestamp=datetime.datetime(2000, 4, 25, 16, 5, 32), user_id=6040),\n",
       " Row(_c0=1, movie_id=2384, rating=4, timestamp=datetime.datetime(2000, 4, 25, 16, 5, 54), user_id=6040),\n",
       " Row(_c0=2, movie_id=593, rating=5, timestamp=datetime.datetime(2000, 4, 25, 16, 5, 54), user_id=6040)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Import Requests CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-02T18:37:23.777883Z",
     "start_time": "2019-07-02T18:37:23.728680Z"
    },
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "'Path does not exist: file:/Users/adam/Documents/flatiron/Virtual-environment/dc_ds_04_22_19/module_5/recommendation_spark_project/recommendation_project/recommendation-case-study/data/requests.csv;'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.4.3/libexec/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o127.csv.\n: org.apache.spark.sql.AnalysisException: Path does not exist: file:/Users/adam/Documents/flatiron/Virtual-environment/dc_ds_04_22_19/module_5/recommendation_spark_project/recommendation_project/recommendation-case-study/data/requests.csv;\n\tat org.apache.spark.sql.execution.datasources.DataSource$$anonfun$org$apache$spark$sql$execution$datasources$DataSource$$checkAndGlobPathIfNecessary$1.apply(DataSource.scala:558)\n\tat org.apache.spark.sql.execution.datasources.DataSource$$anonfun$org$apache$spark$sql$execution$datasources$DataSource$$checkAndGlobPathIfNecessary$1.apply(DataSource.scala:545)\n\tat scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)\n\tat scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241)\n\tat scala.collection.immutable.List.foreach(List.scala:392)\n\tat scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241)\n\tat scala.collection.immutable.List.flatMap(List.scala:355)\n\tat org.apache.spark.sql.execution.datasources.DataSource.org$apache$spark$sql$execution$datasources$DataSource$$checkAndGlobPathIfNecessary(DataSource.scala:545)\n\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:359)\n\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:223)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n\tat org.apache.spark.sql.DataFrameReader.csv(DataFrameReader.scala:615)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-d7c69ce1ff58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'data/requests.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrequests\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minferSchema\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.4.3/libexec/python/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36mcsv\u001b[0;34m(self, path, schema, sep, encoding, quote, escape, comment, header, inferSchema, ignoreLeadingWhiteSpace, ignoreTrailingWhiteSpace, nullValue, nanValue, positiveInf, negativeInf, dateFormat, timestampFormat, maxColumns, maxCharsPerColumn, maxMalformedLogPerPartition, mode, columnNameOfCorruptRecord, multiLine, charToEscapeQuoteEscaping, samplingRatio, enforceSchema, emptyValue)\u001b[0m\n\u001b[1;32m    470\u001b[0m             \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_spark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonUtils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoSeq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    473\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRDD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1284\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1285\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1286\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1288\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.4.3/libexec/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     67\u001b[0m                                              e.java_exception.getStackTrace()))\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.AnalysisException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.catalyst.analysis'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: 'Path does not exist: file:/Users/adam/Documents/flatiron/Virtual-environment/dc_ds_04_22_19/module_5/recommendation_spark_project/recommendation_project/recommendation-case-study/data/requests.csv;'"
     ]
    }
   ],
   "source": [
    "file = 'data/requests.csv'\n",
    "requests = spark.read.csv(file, inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-02T18:37:23.951568Z",
     "start_time": "2019-07-02T18:37:23.945252Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'requests' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-5e482a8a1a83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrequests\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'requests' is not defined"
     ]
    }
   ],
   "source": [
    "requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Import Users CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-02T18:37:53.359863Z",
     "start_time": "2019-07-02T18:37:53.131655Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "file = 'data/users.csv'\n",
    "users = spark.read.csv(file, inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-02T18:38:01.938037Z",
     "start_time": "2019-07-02T18:38:01.840058Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(_c0=0, id=2, gender='M', age=56, occupation='self-employed', zipcode='70072'),\n",
       " Row(_c0=1, id=3, gender='M', age=25, occupation='scientist', zipcode='55117'),\n",
       " Row(_c0=2, id=4, gender='M', age=45, occupation='executive/managerial', zipcode='02460')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read datasets into Pyspark DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-02T18:43:50.568422Z",
     "start_time": "2019-07-02T18:43:50.564392Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- movie_id: integer (nullable = true)\n",
      " |-- rating: integer (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- user_id: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print Schema\n",
    "ratings.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-02T18:43:51.252207Z",
     "start_time": "2019-07-02T18:43:51.232268Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_c0: int, movie_id: int, rating: int, timestamp: timestamp, user_id: int]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-02T18:43:52.829661Z",
     "start_time": "2019-07-02T18:43:51.600443Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------+-------------------+-------+\n",
      "|_c0|movie_id|rating|          timestamp|user_id|\n",
      "+---+--------+------+-------------------+-------+\n",
      "|  0|     858|     4|2000-04-25 16:05:32|   6040|\n",
      "|  1|    2384|     4|2000-04-25 16:05:54|   6040|\n",
      "|  2|     593|     5|2000-04-25 16:05:54|   6040|\n",
      "|  3|    1961|     4|2000-04-25 16:06:17|   6040|\n",
      "|  4|    1419|     3|2000-04-25 16:07:36|   6040|\n",
      "+---+--------+------+-------------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-02T18:47:38.249493Z",
     "start_time": "2019-07-02T18:47:38.243766Z"
    }
   },
   "outputs": [],
   "source": [
    "ratings = ratings.drop(ratings.timestamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting ALS Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train:Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-02T18:47:42.945956Z",
     "start_time": "2019-07-02T18:47:42.628558Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Count: 503570\n",
      "Test Dataset Count: 216379\n"
     ]
    }
   ],
   "source": [
    "(trainingdata, testdata) = ratings.randomSplit([0.7, 0.3], seed = 100)\n",
    "\n",
    "print(\"Training Dataset Count: \" + str(trainingdata.count()))\n",
    "print(\"Test Dataset Count: \" + str(testdata.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-02T18:47:42.988119Z",
     "start_time": "2019-07-02T18:47:42.947801Z"
    }
   },
   "outputs": [],
   "source": [
    "als = ALS(\n",
    "    rank=10,  #10 variables/latent factors\n",
    "    maxIter=10,  #\n",
    "    userCol='user_id',\n",
    "    itemCol='movie_id',\n",
    "    ratingCol='rating',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-02T18:47:45.162047Z",
     "start_time": "2019-07-02T18:47:42.990268Z"
    }
   },
   "outputs": [],
   "source": [
    "als_model = als.fit(trainingdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Model on Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-02T20:08:38.706109Z",
     "start_time": "2019-07-02T20:08:38.645598Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_c0: int, movie_id: int, rating: int, user_id: int, prediction: float]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = als_model.transform(trainingdata)\n",
    "predictions.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-02T20:09:11.667917Z",
     "start_time": "2019-07-02T20:09:11.664429Z"
    }
   },
   "outputs": [],
   "source": [
    "user_factors = als_model.userFactors\n",
    "item_factors = als_model.itemFactors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-02T20:09:18.605796Z",
     "start_time": "2019-07-02T20:09:12.027590Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7966203970798736"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator = RegressionEvaluator(labelCol='rating')\n",
    "evaluator.evaluate(predictions.na.drop())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch for rank on the ALS Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-02T20:21:24.604459Z",
     "start_time": "2019-07-02T20:18:25.432249Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank of 2 gives evaluation of: 0.8692836935677496\n",
      "rank of 3 gives evaluation of: 0.8498860941523478\n",
      "rank of 4 gives evaluation of: 0.8432708835916568\n",
      "rank of 5 gives evaluation of: 0.8300134886200013\n",
      "rank of 6 gives evaluation of: 0.8168416618464474\n",
      "rank of 7 gives evaluation of: 0.8142698576875608\n",
      "rank of 8 gives evaluation of: 0.8073526060419344\n",
      "rank of 9 gives evaluation of: 0.8014436953738617\n",
      "rank of 10 gives evaluation of: 0.7966203970798736\n",
      "rank of 11 gives evaluation of: 0.7920560493865898\n",
      "rank of 12 gives evaluation of: 0.7868691369468591\n",
      "rank of 13 gives evaluation of: 0.7838049648715684\n",
      "rank of 14 gives evaluation of: 0.7805271499584969\n",
      "rank of 15 gives evaluation of: 0.7770812532800946\n",
      "rank of 16 gives evaluation of: 0.7759755304138988\n",
      "rank of 17 gives evaluation of: 0.7723151487228088\n",
      "rank of 18 gives evaluation of: 0.7700858450399435\n",
      "rank of 19 gives evaluation of: 0.7674571313808766\n"
     ]
    }
   ],
   "source": [
    "for rank in range(2,20):\n",
    "    als = ALS(\n",
    "    rank=rank,  #10 variables/latent factors\n",
    "    maxIter=10,  #\n",
    "    userCol='user_id',\n",
    "    itemCol='movie_id',\n",
    "    ratingCol='rating',\n",
    "    )\n",
    "    \n",
    "    als_model = als.fit(trainingdata)\n",
    "    \n",
    "    predictions = als_model.transform(trainingdata)\n",
    "    predictions.persist()\n",
    "    \n",
    "    evaluator = RegressionEvaluator(labelCol='rating')\n",
    "    train_evaluation = evaluator.evaluate(predictions.na.drop())\n",
    "    print('rank of {} gives evaluation of: {}'.format(rank, train_evaluation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Rank of 19 seems to produce the best results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate ALS Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-02T20:25:36.325298Z",
     "start_time": "2019-07-02T20:25:36.279878Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_c0: int, movie_id: int, rating: int, user_id: int, prediction: float]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = als_model.transform(testdata)\n",
    "predictions.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-02T20:25:36.573230Z",
     "start_time": "2019-07-02T20:25:36.530403Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------+-------+\n",
      "|_c0|movie_id|rating|user_id|\n",
      "+---+--------+------+-------+\n",
      "|  0|     858|     4|   6040|\n",
      "+---+--------+------+-------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-02T20:25:41.889202Z",
     "start_time": "2019-07-02T20:25:36.791635Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+------+-------+----------+\n",
      "|   _c0|movie_id|rating|user_id|prediction|\n",
      "+------+--------+------+-------+----------+\n",
      "|388719|     148|     4|   3184| 2.9916844|\n",
      "+------+--------+------+-------+----------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-02T20:25:46.394339Z",
     "start_time": "2019-07-02T20:25:46.388559Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: int, features: array<float>]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_factors = als_model.userFactors\n",
    "user_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-02T20:25:47.394355Z",
     "start_time": "2019-07-02T20:25:47.388956Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: int, features: array<float>]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_factors = als_model.itemFactors\n",
    "item_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-02T20:25:55.344836Z",
     "start_time": "2019-07-02T20:25:55.024666Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8788509480050949"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator = RegressionEvaluator(labelCol='rating')\n",
    "test_evaluation = evaluator.evaluate(predictions.na.drop())\n",
    "test_evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Will User Like a Certain Movie?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-02T18:47:53.301416Z",
     "start_time": "2019-07-02T18:47:53.207553Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-f0298d95b0af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# User\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0muser_row\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muser_factors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser_factors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfirst\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0muser_factors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_row\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'features'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0muser_factors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# User\n",
    "user_row = user_factors[user_factors['id'] == 10].first()\n",
    "user_factors = np.array(user_row['features'])\n",
    "user_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-02T18:47:53.303829Z",
     "start_time": "2019-07-02T18:47:42.653Z"
    }
   },
   "outputs": [],
   "source": [
    "# Movie\n",
    "movie_row = item_factors[item_factors['id'] == 296].first()\n",
    "movie_factors = np.array(movie_row['features'])\n",
    "movie_factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dot Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-02T18:47:53.304510Z",
     "start_time": "2019-07-02T18:47:42.656Z"
    }
   },
   "outputs": [],
   "source": [
    "user_factors @ movie_factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-02T18:47:53.305483Z",
     "start_time": "2019-07-02T18:47:42.659Z"
    }
   },
   "outputs": [],
   "source": [
    "user_preds = predictions[predictions['userId'] == 10]\n",
    "user_preds.sort('movieId').show()\n",
    "!grep 296 < data/movies.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# What Movies will a User Like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-02T18:47:53.306798Z",
     "start_time": "2019-07-02T18:47:42.661Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "recs = als_model.recommendForAllUsers(numItems=10)\n",
    "recs[recs['userId']==10].first()['recommendations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-02T18:47:53.307975Z",
     "start_time": "2019-07-02T18:47:42.664Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "top_movie = None # put a number here/movieID\n",
    "!grep top_movie < data/movies.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cold Start Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Machine Learning in Recommendation Systems**\n",
    "\n",
    "ML is only used in the best recommendation systems. The model is constantly learning and adapting to platforms’ users and products it sells. Enables platform to optimize and personalize the content for every particular user.\n",
    "\n",
    "**Cold Start Problem**\n",
    "\n",
    "success strongly depends on the platform’s capabilities to adapt quickly to a new person or a new search in order to provide the best and personalized service.\n",
    "\n",
    "**Product vs Visitor Cold Start**\n",
    "\n",
    "Can get both types, i.e a new movie or new visitor on platform.  \n",
    "\n",
    "Use content-based filtering to address this challenge: \n",
    "* First use the metadata of new products while creating recommendations\n",
    "* Visitor’s actions are not used until a certain period of time, i.e. we know enough about them\n",
    "\n",
    "**Best Strategy for Visitor Cold Start**\n",
    "\n",
    "Use popularity based recommendations\n",
    "* regional trends, e.g. global, local\n",
    "* Time based trends, e.g. time of day, time of year\n",
    "* Geolocation, e.g. zipcode, region, country\n",
    "* Platform, e.g. mobile, desktop\n",
    "\n",
    "Make Clusters within these categories\n",
    "* Kmeans\n",
    "* Want high scores, but with tight confidence intervals\n",
    "\n",
    "**Penalizing Some User Types**\n",
    "\n",
    "Can even distinguish between users and how they jump between different movies.  If they jump around a lot, can weight their recommendations.\n",
    "\n",
    "**Limitations**\n",
    "* ALS is limited in how to deal with NaNs, as we have to drop them.  Doesn't work so well in reality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_means = KMeans(n_clusters=3) # Must set number of clusters at initialization time!\n",
    "k_means.fit(trainingdata) # Run the clustering algorithm\n",
    "cluster_assignments = k_means.predict(trainingdata) # Generate cluster index values for each row in df\n",
    "\n",
    "print(calinski_harabaz_score(trainingdata, cluster_assignments))\n",
    "\n",
    "# Calculate silhouette score\n",
    "labels = k_means.labels_\n",
    "metrics.silhouette_score(trainingdata, labels, metric='euclidean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
